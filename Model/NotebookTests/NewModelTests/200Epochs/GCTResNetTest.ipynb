{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50 Epochs, GCT attention, Dali Aug Without ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parameters\n",
    "Here you can change some of the main parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "new_aug_epoch_distance = 5 #how many epochs between new augmentations\n",
    "number_of_augmentations = 3\n",
    "\n",
    "show_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENSLIDE_PATH = r'D:\\Estudos\\IC\\Libraries\\openslide-bin-4.0.0.3-windows-x64\\openslide-bin-4.0.0.3-windows-x64\\bin'\n",
    "\n",
    "import os\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "else:\n",
    "    import openslide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "from torchvision import ops\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms.functional as TF\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "sys.path.append(r'D:\\Estudos\\IC\\CNN\\CNN\\Model')\n",
    "from TrainingDataArrangement import arrange_data\n",
    "import CustomDataset\n",
    "from UNetModel import UNet\n",
    "from DaliDataAug import load_pil_image, data_augmentation\n",
    "\n",
    "\n",
    "#defining device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):  \n",
    "    random.seed(seed) #setting for albumentations\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(727)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting path references\n",
    "testing_folders = [\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009009\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009010x1000902\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009011\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009014\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009016x1000903\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009023\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009009\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009010x1000902\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009011\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009014\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009016x1000903\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009023\\02-non_roi\"\n",
    "]\n",
    "\n",
    "training_folders = [\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\01-roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\02-non_roi\",\n",
    "    # # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\02-non_roi\"\n",
    "]\n",
    "resnet_training_folders = [\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\02-non_roi\"\n",
    "]\n",
    "\n",
    "\n",
    "updated_training_folders = []\n",
    "updated_testing_folders = []\n",
    "updated_resnet_training_folders = []\n",
    "\n",
    "for training_folder, testing_folder in zip(training_folders, testing_folders):\n",
    "    original_training_folder = training_folder + \"\\\\01-original\"\n",
    "    mask_training_folder = training_folder + \"\\\\02-mask\"\n",
    "    updated_training_folders.extend([original_training_folder, mask_training_folder])\n",
    "\n",
    "    original_testing_folder = testing_folder + \"\\\\01-original\"\n",
    "    mask_testing_folder = testing_folder + \"\\\\02-mask\"\n",
    "    updated_testing_folders.extend([original_testing_folder, mask_testing_folder])\n",
    "\n",
    "for training_folder in resnet_training_folders:\n",
    "    original_training_folder = training_folder + \"\\\\01-original\"\n",
    "    mask_training_folder = training_folder + \"\\\\02-mask\"\n",
    "    updated_resnet_training_folders.extend([original_training_folder, mask_training_folder])\n",
    "\n",
    "training_path = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\training\"\n",
    "test_path = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\"\n",
    "resnet_training_path = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\resnet_training\"\n",
    "\n",
    "arrange_data(test_path,updated_testing_folders)\n",
    "arrange_data(training_path,updated_training_folders)\n",
    "arrange_data(resnet_training_path,updated_resnet_training_folders)\n",
    "\n",
    "#data augmentation\n",
    "augmentation_transform = A.Compose([\n",
    "    #A.ToPIL(),\n",
    "    A.Resize(width = width, height = height, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    A.Transpose(p=0.25),\n",
    "    #A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
    "    # A.GridDistortion(num_steps=5, distort_limit=(-0.3, 0.3), interpolation=1, border_mode=4, p=0.3),\n",
    "    # A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1, border_mode=4, p=0.3),\n",
    "    # A.OpticalDistortion(distort_limit=(-0.05, 0.05), shift_limit=(-0.05, 0.05), interpolation=1, border_mode=4, p=0.3),\n",
    "    # A.Perspective(scale=(0.05, 0.1), keep_size=True, pad_mode=0, pad_val=0, mask_pad_val=0, fit_output=False, interpolation=1, p=0.3),\n",
    "    # A.PiecewiseAffine (scale=(0.03, 0.05), nb_rows=4, nb_cols=4, interpolation=1, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=0.1),\n",
    "    # A.ShiftScaleRotate (shift_limit=(-0.0625, 0.0625), scale_limit=(-0.1, 0.1), rotate_limit=(-45, 45), interpolation=1, border_mode=4, value=0, mask_value=0, rotate_method='largest_box', p=0.15),\n",
    "    ToTensorV2()  # loading image to tensor and normalization\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    #A.ToPIL(),\n",
    "    A.Resize(width = width, height = height, p=1.0),\n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.VerticalFlip(p=0.25),\n",
    "    #A.RandomRotate90(p=0.5),\n",
    "    #A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    #A.Transpose(p=0.5),\n",
    "    #A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
    "    ToTensorV2()  # loading image to tensor and normalization\n",
    "])\n",
    "\n",
    "print(\"Showing images:\", show_images)\n",
    "\n",
    "print(\"Getting the images\")\n",
    "training_dataset = CustomDataset.CustomImageDataset(training_path + \"\\\\images\", training_path + \"\\\\masks\", transform=augmentation_transform)\n",
    "test_dataset = CustomDataset.CustomImageDataset(test_path + \"\\\\images\", test_path + \"\\\\masks\", transform=test_transform)\n",
    "\n",
    "resnet_dataset = CustomDataset.CustomImageDataset(resnet_training_path + \"\\\\images\", resnet_training_path + \"\\\\masks\", transform=augmentation_transform)\n",
    "resnet_dataloader = DataLoader(resnet_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Converting images to tensors\")\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=batch_size, shuffle=False)\n",
    "if(show_images):\n",
    "    num_images_to_display = 10\n",
    "    fig, axs = plt.subplots(num_images_to_display, 2, figsize=(10, 20))\n",
    "    for i in range(num_images_to_display):\n",
    "        train_image, mask_image = training_dataset[i]\n",
    "        train_image = train_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "        axs[i, 0].imshow(train_image)\n",
    "        axs[i, 0].set_title('Train Image')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        mask_image = mask_image.squeeze(0).numpy()\n",
    "        axs[i, 1].imshow(mask_image, cmap='gray')\n",
    "        axs[i, 1].set_title('Mask Image')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dir Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dir_checker_and_restarter(images_dir):\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    for filename in os.listdir(images_dir): #deleting all previous images files\n",
    "        file_path = os.path.join(images_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "def save_image(image, path):\n",
    "    image.save(path)\n",
    "\n",
    "def recreate_data_loader(number_of_augmentations = 5):\n",
    "    input_dir_train = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\training\"\n",
    "    output_dir_train = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\training\\transformed\"\n",
    "\n",
    "    input_dir_test = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\"\n",
    "    output_dir_test = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\transformed\"\n",
    "\n",
    "    main_dirs = [output_dir_train, output_dir_test]\n",
    "\n",
    "    for dir in main_dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir + \"\\images\")\n",
    "            os.makedirs(dir + \"\\masks\")\n",
    "        else:\n",
    "            dir_checker_and_restarter(dir)\n",
    "\n",
    "    augmentation = [\"horizontal_flip\", \"vertical_flip\", \"rotation\", \"transpose\"]\n",
    "\n",
    "    img_input_size = (640, 640)\n",
    "    img_output_size = (width, height)\n",
    "\n",
    "    input_output_mapping = {\n",
    "        \"training\": output_dir_train,\n",
    "        \"testing\": output_dir_test\n",
    "    }\n",
    "\n",
    "    dirs = [input_dir_train, input_dir_test]\n",
    "    for i in range(number_of_augmentations):\n",
    "        for dir in dirs:\n",
    "            img_path_appended = os.path.join(dir, \"images\")\n",
    "            mask_path_appended = os.path.join(dir, \"masks\")\n",
    "\n",
    "            image_files = [f for f in os.listdir(img_path_appended) if f.endswith(('.jpg', '.png', '.jpeg', 'tif'))]\n",
    "            mask_files = [f for f in os.listdir(mask_path_appended) if f.endswith(('.jpg', '.png', '.jpeg', 'tif'))]\n",
    "\n",
    "            for img_name, mask_name in zip(image_files, mask_files):\n",
    "                img_path = os.path.join(img_path_appended, img_name)\n",
    "                mask_path = os.path.join(mask_path_appended, mask_name)\n",
    "\n",
    "                input_image = load_pil_image(img_path, False)\n",
    "                mask = load_pil_image(mask_path, False)\n",
    "\n",
    "                target_image = None\n",
    "                GAN_model = None\n",
    "\n",
    "                augmented_img, augmented_mask, used_augmentations = data_augmentation(input_image, target_image, mask, img_input_size, img_output_size, augmentation, GAN_model)\n",
    "\n",
    "                for key in input_output_mapping:\n",
    "                    if key in dir:\n",
    "                        output_dir = input_output_mapping[key]\n",
    "                        break\n",
    "                    \n",
    "                output_img_path = os.path.join(output_dir, f\"images\\\\aug{i}_{img_name}\")\n",
    "                output_mask_path = os.path.join(output_dir, f\"masks\\\\aug{i}_{mask_name}\")\n",
    "                save_image(TF.to_pil_image(augmented_img), output_img_path)\n",
    "                save_image(TF.to_pil_image(augmented_mask), output_mask_path)\n",
    "    print(f\"Finished loading {number_of_augmentations} new augmentations in the whole dataset\")\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    training_dataset = CustomDataset.CustomImageDataset(output_dir_train + \"\\\\images\", output_dir_train + \"\\\\masks\", transform=test_transform)\n",
    "    test_dataset = CustomDataset.CustomImageDataset(output_dir_test + \"\\\\images\", output_dir_test + \"\\\\masks\", transform=test_transform)\n",
    "    train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset , batch_size=batch_size, shuffle=False)\n",
    "    return train_dataloader, test_dataloader\n",
    "train_dataloader, test_dataloader = recreate_data_loader(number_of_augmentations)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_width = width\n",
    "gradcam_height = height\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.6):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (gradcam_width, gradcam_height))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    mask_path = img_path.replace(r\"\\testing\\images\", r\"\\testing\\masks\")\n",
    "    mask = cv2.imread(mask_path)\n",
    "    mask = cv2.resize(mask, (gradcam_width, gradcam_height))\n",
    "\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.5)\n",
    "    plt.title(\"Original Mask With Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def make_gradcam_heatmap(img_tensor, model, target_layer):\n",
    "    model.eval()\n",
    "    \n",
    "    features = None\n",
    "    gradients = None\n",
    "    \n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output\n",
    "    \n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_out[0]\n",
    "    \n",
    "    handle_forward = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_backward = target_layer.register_full_backward_hook(backward_hook)\n",
    "    \n",
    "    with amp.autocast():\n",
    "        preds = model(img_tensor)\n",
    "        pred_class = preds.argmax(dim=1)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    class_score = preds[:, pred_class].squeeze().sum()\n",
    "    class_score.backward(retain_graph=True)\n",
    "    \n",
    "    handle_forward.remove()\n",
    "    handle_backward.remove()\n",
    "    \n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    for i in range(features.shape[1]):\n",
    "        features[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "    heatmap = features.mean(dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)\n",
    "    epsilon = 1e-8\n",
    "    heatmap_max = np.max(heatmap)\n",
    "    heatmap = heatmap / (heatmap_max + epsilon)\n",
    "    \n",
    "    del features, gradients\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def make_prediction_and_visualize(image_paths):\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (gradcam_width, gradcam_height))\n",
    "        img_tensor = torch.tensor(img / 255.0).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "        target_layer = model.upconv2\n",
    "\n",
    "        heatmap = make_gradcam_heatmap(img_tensor.to(device), model, target_layer)\n",
    "\n",
    "        save_and_display_gradcam(img_path, heatmap)\n",
    "\n",
    "def generate_heatmap(img_path): \n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (gradcam_width, gradcam_height))\n",
    "    img_tensor = torch.tensor(img / 255.0).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    target_layer = model.upconv2\n",
    "    return make_gradcam_heatmap(img_tensor.to(device), model, target_layer)\n",
    "\n",
    "def generate_heatmap_with_tensor(img): \n",
    "    target_layer = model.upconv2\n",
    "    return make_gradcam_heatmap(img.unsqueeze(0), model, target_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# image_paths = [\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r27c5.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r27c10.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r28c12.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r31c0.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r31c1.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r35c4.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r35c8.png\",\n",
    "#     r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\\images\\1009009_r35c10.png\",\n",
    "# ]\n",
    "\n",
    "# make_prediction_and_visualize(image_paths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ResNet_GradCam(image, index):\n",
    "    target_layers = [model_resnet.layer4[-1]]\n",
    "    \n",
    "    input_tensor = image\n",
    "\n",
    "    targets = [ClassifierOutputTarget(1)]\n",
    "\n",
    "    def denormalize(image):\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).to(device).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).to(device).view(3, 1, 1)\n",
    "\n",
    "        image = image * std + mean\n",
    "        return image\n",
    "\n",
    "    def to_numpy_uint8(image):\n",
    "        image = image.detach().cpu().numpy()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        image = np.clip(image, 0, 1)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        return image\n",
    "\n",
    "    image_to_show = denormalize(image[index])\n",
    "    image_to_show = to_numpy_uint8(image_to_show)\n",
    "    image_to_show = image_to_show / 255\n",
    "\n",
    "    with GradCAM(model=model_resnet, target_layers=target_layers) as cam:\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        return show_cam_on_image(image_to_show, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        #model_outputs = cam.outputs\n",
    "\n",
    "\n",
    "model_resnet = resnet50(pretrained=True)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 2)\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-4)\n",
    "\n",
    "resnet_epochs = epochs #// 2\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(resnet_epochs):\n",
    "    model_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, masks in tqdm(resnet_dataloader, desc=f'Epoch {epoch + 1}/{resnet_epochs}', leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Create labels: 1 if any mask > 0, else 0\n",
    "        labels = torch.tensor([1 if torch.any(mask > 0) else 0 for mask in masks], dtype=torch.long, device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_resnet(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(resnet_dataloader.dataset)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{resnet_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, resnet_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, resnet_epochs + 1), train_accuracies, color='green', label='Training Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image = []\n",
    "mask = []\n",
    "\n",
    "model_resnet.eval()\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(train_dataloader):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        if torch.any(masks > 0):\n",
    "            test_image_resnet = images[0].detach()\n",
    "            image = test_image_resnet\n",
    "            mask = masks[0].detach()\n",
    "            break\n",
    "\n",
    "first_image_batch = test_image_resnet.unsqueeze(0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cam_image = generate_ResNet_GradCam(first_image_batch, 0)\n",
    "plt.imshow(cam_image)\n",
    "plt.title('Grad-CAM')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "def denormalize(image):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = image.cpu().numpy().transpose((1, 2, 0))\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image\n",
    "\n",
    "image_to_show = denormalize(image)\n",
    "plt.imshow(image_to_show)\n",
    "plt.imshow(mask.cpu().numpy()[0], alpha=0.5, cmap='plasma')\n",
    "plt.title('Image with Mask Overlay')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "classes = 1\n",
    "model = UNet(channels, classes, use_attention=True, attention_type=\"GCT_Attention\")\n",
    "input_data = torch.randn(1, channels, width, height)\n",
    "output = model(input_data)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = epochs\n",
    "\n",
    "training_accuracies = []\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images_dir = \"epoch_images\"\n",
    "dir_checker_and_restarter(images_dir)\n",
    "for images, masks in test_dataloader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    if torch.any(masks > 0):\n",
    "        first_image_in_dataset = images[0].detach()\n",
    "        break\n",
    "first_image_batch = first_image_in_dataset.unsqueeze(0)\n",
    "resnet_img = generate_ResNet_GradCam(first_image_batch, 0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "\n",
    "    for images, masks in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = F.binary_cross_entropy(outputs, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #thresholding the prediction values\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        binary_predictions = (outputs > 0.5).float()\n",
    "        \n",
    "        #calculating the correct pixels\n",
    "        correct_predictions += (binary_predictions == masks).sum().item()\n",
    "\n",
    "        total_samples += masks.numel()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    training_accuracies.append(epoch_accuracy)\n",
    "    training_losses.append(epoch_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%\")\n",
    "\n",
    "    #validation\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0   \n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in tqdm(test_dataloader, desc='Validation', leave=False):\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "\n",
    "            val_loss += F.binary_cross_entropy(val_outputs, val_masks).item()\n",
    "\n",
    "            val_binary_predictions = (val_outputs > 0.5).float()\n",
    "\n",
    "            val_correct_predictions += (val_binary_predictions == val_masks).sum().item()\n",
    "\n",
    "            val_total_samples += val_masks.numel()\n",
    "\n",
    "    val_epoch_loss = val_loss / len(test_dataloader)\n",
    "    val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy * 100:.2f}%\\n\")\n",
    "    print(\"============================================\")\n",
    "            \n",
    "\n",
    "    if(show_images):\n",
    "        heatmap = generate_heatmap_with_tensor(first_image_in_dataset.to(device).half())#making heatmap only of the first image of the batch\n",
    "        with torch.no_grad():\n",
    "            for images, masks in test_dataloader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                if torch.any(masks > 0):\n",
    "                    \n",
    "                    outputs = model(images)\n",
    "                    probs = outputs\n",
    "                    images_np = images.cpu().numpy()\n",
    "                    masks_np = masks.cpu().numpy()\n",
    "                    probs_np = probs.cpu().numpy()\n",
    "                    threshold = 0.5\n",
    "                    preds_np = (probs_np > threshold).astype(np.uint8)\n",
    "                    preds_np_squeezed = np.squeeze(preds_np, axis=1) \n",
    "                    plt.figure(figsize=(16, 8))\n",
    "                    plt.subplot(1, 4, 1)\n",
    "                    plt.imshow(images_np[0].transpose((1, 2, 0)))\n",
    "                    plt.imshow(masks_np[0, 0], alpha=0.5, cmap='plasma')\n",
    "                    plt.title(\"Original Image with Ground Truth Mask\")\n",
    "                    plt.axis('off')\n",
    "                    plt.subplot(1, 4, 2)\n",
    "                    plt.imshow(images_np[0].transpose((1, 2, 0)))\n",
    "                    plt.imshow(preds_np_squeezed[0], alpha=0.5, cmap='plasma')\n",
    "                    plt.title(\"Predicted Mask\" + f\" ({val_epoch_accuracy * 100:.2f}%)\" + f\"Epoch {epoch + 1}\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    #gradcam heatmap\n",
    "                    img = first_image_in_dataset.cpu().detach().permute(1, 2, 0).numpy()\n",
    "                    img = (img - img.min()) / (img.max() - img.min()) #normalizing\n",
    "                    img = np.uint8(255 * img)\n",
    "\n",
    "                    heatmap = np.uint8(255 * heatmap)\n",
    "                    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "                    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "                    superimposed_img = cv2.addWeighted(heatmap, 0.6, img, 1 - 0.6, 0)\n",
    "\n",
    "                    plt.subplot(1, 4, 3)\n",
    "                    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('GradCAM with Overlay')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 4, 4)\n",
    "                    plt.imshow(resnet_img)\n",
    "                    plt.title('GradCAM ResNet')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    #saving the figs for the gif\n",
    "                    plt.savefig(os.path.join(images_dir, f'epoch_{epoch + 1}.png'))\n",
    "                    if epoch % 5 == 0: plt.show()\n",
    "                    plt.close()\n",
    "                    break\n",
    "    if epoch % new_aug_epoch_distance == 0 and epoch != 0: #dynamic data loader changing to improve loss\n",
    "        train_dataloader, test_dataloader = recreate_data_loader(number_of_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "\n",
    "images = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    images.append(imageio.v2.imread(os.path.join(images_dir, f'epoch_{epoch}.png')))\n",
    "\n",
    "gif_path = os.path.join(images_dir, 'training_progress.gif')\n",
    "imageio.mimsave(gif_path, images, duration=1, loop=0)\n",
    "\n",
    "from IPython import display\n",
    "display.Image(gif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "- **Accuracy**: The number of correct predictions out of the total of predictions. Higher means better.\n",
    "\n",
    "- **Loss**: How well the predictions matched the expected result. Lower means better.\n",
    "\n",
    "- **Dice**: Calculates the similarity between the intersection of two images. Higher means better.\n",
    "\n",
    "- **Intersection over Union (IoU)**: It calculates the overlap between the predicted image and the ground truth, but it also takes in consideration the union of the boxes, while Dice only accounts for the intersection.Higher means better.\n",
    "\n",
    "- **Panoptic Quality (PQ)**: Indicates the performance in segmenting instances accurately. Higher means better.\n",
    "\n",
    "- **Aggregated Jaccard Index (AJI)**: Indicate the performance of the alignment between predicted and ground truth instance boundaries. Higher means better.\n",
    "\n",
    "- **Specificity**: Measures the proportion of actual negatives that are correctly identified. Higher means better.\n",
    "\n",
    "- **Sensitivity**: Measures the proportion of actual positives that are correctly identified. Higher means better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(predictions, targets):\n",
    "    true_positives = ((predictions == 1) & (targets == 1)).sum().item()\n",
    "    true_negatives = ((predictions == 0) & (targets == 0)).sum().item()\n",
    "    false_positives = ((predictions == 1) & (targets == 0)).sum().item()\n",
    "    false_negatives = ((predictions == 0) & (targets == 1)).sum().item()\n",
    "    \n",
    "    intersection = torch.logical_and(predictions, targets).sum().item()\n",
    "    union = torch.logical_or(predictions, targets).sum().item()\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives, intersection, union\n",
    "\n",
    "model.eval()\n",
    "accuracies = []\n",
    "losses = []\n",
    "dices = [] \n",
    "ious = []\n",
    "specificities = []\n",
    "sensitivities = []\n",
    "pqs = []\n",
    "ajis = []\n",
    "\n",
    "ev_running_loss = 0.0\n",
    "ev_correct_predictions = 0\n",
    "ev_total_samples = 0\n",
    "ev_true_positives = 0\n",
    "ev_true_negatives = 0\n",
    "ev_false_positives = 0\n",
    "ev_false_negatives = 0\n",
    "ev_aji = 0\n",
    "batch_iou = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ev_images, ev_masks in test_dataloader:\n",
    "        ev_images, ev_masks = ev_images.to(device), ev_masks.to(device)\n",
    "        ev_outputs = model(ev_images)\n",
    "        ev_loss = F.binary_cross_entropy(ev_outputs, ev_masks)\n",
    "        ev_running_loss += ev_loss.item()\n",
    "        losses.append(ev_loss.item())\n",
    "\n",
    "        #Thresholding the prediction values\n",
    "        ev_binary_predictions = (ev_outputs > 0.5).float()\n",
    "\n",
    "        #Calculating the correct pixels\n",
    "        ev_correct_predictions += (ev_binary_predictions == ev_masks).sum().item()\n",
    "        ev_total_samples += ev_masks.numel()\n",
    "\n",
    "        #Calculate metrics\n",
    "        tp, tn, fp, fn, intersection, union = calculate_metrics(ev_binary_predictions, ev_masks)\n",
    "        \n",
    "        ev_true_positives += tp\n",
    "        ev_true_negatives += tn\n",
    "        ev_false_positives += fp\n",
    "        ev_false_negatives += fn\n",
    "        \n",
    "        #Calculating IoU\n",
    "        iou = intersection / union if union > 0 else 0.0\n",
    "        batch_iou += iou\n",
    "        ious.append(iou)\n",
    "\n",
    "        #Calculating AJI\n",
    "        aji_numerator = intersection\n",
    "        aji_denominator = union + fp + fn\n",
    "        aji = aji_numerator / aji_denominator if aji_denominator > 0 else 0.0\n",
    "        ev_aji += aji\n",
    "        ajis.append(aji)\n",
    "\n",
    "        #Calculate accuracy\n",
    "        batch_accuracy = (ev_binary_predictions == ev_masks).sum().item() / ev_masks.numel()\n",
    "        accuracies.append(batch_accuracy)\n",
    "\n",
    "        #Calculate Dice coefficient\n",
    "        dice_coefficient = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n",
    "        dices.append(dice_coefficient)\n",
    "\n",
    "        #Precision and recall\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        pqs.append(precision * recall if precision + recall > 0 else 0.0)\n",
    "        \n",
    "        #Specificity and sensitivity\n",
    "        sensitivities.append(recall)\n",
    "        specificities.append(tn / (tn + fp) if (tn + fp) > 0 else 0.0)\n",
    "\n",
    "#Precision and recall\n",
    "precision = ev_true_positives / (ev_true_positives + ev_false_positives) if (ev_true_positives + ev_false_positives) > 0 else 0.0\n",
    "recall = ev_true_positives / (ev_true_positives + ev_false_negatives) if (ev_true_positives + ev_false_negatives) > 0 else 0.0\n",
    "\n",
    "#Specificity and sensitivity\n",
    "ev_sensitivity = recall\n",
    "ev_specificity = ev_true_negatives / (ev_true_negatives + ev_false_positives) if (ev_true_negatives + ev_false_positives) > 0 else 0.0\n",
    "\n",
    "#Evaluation loss and accuracy\n",
    "ev_loss = ev_running_loss / len(test_dataloader)\n",
    "ev_accuracy = ev_correct_predictions / ev_total_samples\n",
    "\n",
    "#Dice coefficient\n",
    "ev_temp_dice = (2 * ev_true_positives) / (2 * ev_true_positives + ev_false_positives + ev_false_negatives) if (2 * ev_true_positives + ev_false_positives + ev_false_negatives) > 0 else 0.0\n",
    "\n",
    "#PQ\n",
    "ev_pq = precision * recall if precision + recall > 0 else 0.0\n",
    "\n",
    "#IoU\n",
    "iou = batch_iou / len(test_dataloader)\n",
    "\n",
    "#AJI\n",
    "aji = ev_aji / len(test_dataloader)\n",
    "\n",
    "#Calculate standard deviation\n",
    "loss_std = np.std(losses)\n",
    "accuracy_std = np.std(accuracies)\n",
    "dice_std = np.std(dices)\n",
    "iou_std = np.std(ious)\n",
    "specificity_std = np.std(specificities)\n",
    "sensitivity_std = np.std(sensitivities)\n",
    "pq_std = np.std(pqs)\n",
    "aji_std = np.std(ajis)\n",
    "\n",
    "print(f'Evaluation Loss: {ev_loss * 100:0.2f}% (Std: {loss_std * 100:0.2f}%)')\n",
    "print(f'Evaluation Accuracy: {ev_accuracy * 100:0.2f}% (Std: {accuracy_std * 100:0.2f}%)')\n",
    "print(f'Dice Coefficient: {ev_temp_dice * 100:0.2f}% (Std: {dice_std * 100:0.2f}%)')\n",
    "print(f'IoU: {iou * 100:0.2f}% (Std: {iou_std * 100:0.2f}%)')\n",
    "print(f'Specificity: {ev_specificity * 100:0.2f}% (Std: {specificity_std * 100:0.2f}%)')\n",
    "print(f'Sensitivity: {ev_sensitivity * 100:0.2f}% (Std: {sensitivity_std * 100:0.2f}%)')\n",
    "print(f'PQ: {ev_pq * 100:0.2f}% (Std: {pq_std * 100:0.2f}%)')\n",
    "print(f'AJI: {aji * 100:0.2f}% (Std: {aji_std * 100:0.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Charts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "def to_cpu_and_numpy(data):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return data.cpu().numpy()\n",
    "    return data\n",
    "\n",
    "training_losses = [to_cpu_and_numpy(loss) for loss in training_losses]\n",
    "val_losses = [to_cpu_and_numpy(loss) for loss in val_losses]\n",
    "training_accuracies = [to_cpu_and_numpy(acc) for acc in training_accuracies]\n",
    "val_accuracies = [to_cpu_and_numpy(acc) for acc in val_accuracies]\n",
    "\n",
    "plt.plot(epochs_list, training_losses, label='Training Loss', color='blue')\n",
    "plt.plot(epochs_list, val_losses, label='Validation Loss', color='orange')\n",
    "plt.plot(epochs_list, training_accuracies, label='Training Accuracy', color='green')\n",
    "plt.plot(epochs_list, val_accuracies, label='Validation Accuracy', color='red')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training and Validation Metrics')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_images:\n",
    "    counter = 0\n",
    "    brightness = 0.5\n",
    "    for images, masks in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            images_normalized = images\n",
    "\n",
    "            outputs = model(images_normalized)\n",
    "            probs = outputs\n",
    "            #probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            images_np = images_normalized.cpu().numpy()\n",
    "            masks_np = masks.cpu().numpy()\n",
    "            probs_np = probs.cpu().numpy()\n",
    "\n",
    "            threshold = 0.5\n",
    "            preds_np = (probs_np > threshold).astype(np.uint8)\n",
    "            preds_np_squeezed = np.squeeze(preds_np, axis=1) \n",
    "\n",
    "            original_image = images_np[0].transpose((1, 2, 0))\n",
    "            ground_truth_mask = masks_np[0, 0]\n",
    "            predicted_mask = preds_np_squeezed[0]\n",
    "            probability_map = probs_np[0, 0]\n",
    "\n",
    "            overlay_gt = original_image.copy()\n",
    "            overlay_gt = original_image * brightness # to make it a little darker\n",
    "            overlay_gt[ground_truth_mask == 1] = [1, 1, 0]\n",
    "\n",
    "            overlay_pred = original_image.copy()\n",
    "            overlay_pred = original_image * brightness\n",
    "            overlay_pred[predicted_mask == 1] = [0, 1, 1]\n",
    "\n",
    "            overlay_diff = original_image.copy()\n",
    "            overlay_diff = original_image * brightness \n",
    "            overlay_diff[(ground_truth_mask == 1) & (predicted_mask == 1)] = [0, 1, 0]  #correct predictions\n",
    "            overlay_diff[(ground_truth_mask == 1) & (predicted_mask == 0)] = [1, 0, 0]  #missed predictions\n",
    "            overlay_diff[(ground_truth_mask == 0) & (predicted_mask == 1)] = [0, 0, 1]  #false positives\n",
    "\n",
    "            plt.figure(figsize=(28, 4))\n",
    "\n",
    "            plt.subplot(1, 7, 1)\n",
    "            plt.imshow(original_image)\n",
    "            plt.title(\"Original Image\")\n",
    "\n",
    "            plt.subplot(1, 7, 2)\n",
    "            plt.imshow(ground_truth_mask, cmap='gray')\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "\n",
    "            plt.subplot(1, 7, 3)\n",
    "            plt.imshow(probability_map, cmap='plasma')\n",
    "            plt.title(\"Probability Map\")\n",
    "\n",
    "            plt.subplot(1, 7, 4)\n",
    "            plt.imshow(predicted_mask, cmap='gray')\n",
    "            plt.title(\"Predicted Mask\")\n",
    "\n",
    "            plt.subplot(1, 7, 5)\n",
    "            plt.imshow(overlay_gt)\n",
    "            plt.title(\"Overlay Ground Truth\")\n",
    "\n",
    "            plt.subplot(1, 7, 6)\n",
    "            plt.imshow(overlay_pred)\n",
    "            plt.title(\"Overlay Pred\")\n",
    "\n",
    "            green_patch = mpatches.Patch(color='green', label='True Positive')\n",
    "            red_patch = mpatches.Patch(color='red', label='False Negative')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='False Positive')\n",
    "            plt.subplot(1, 7, 7)\n",
    "            plt.imshow(overlay_diff)\n",
    "            plt.title(\"Overlay Diff\")\n",
    "            plt.legend(handles=[green_patch, red_patch, blue_patch], loc='upper right')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        #showing gradcams\n",
    "        resnet_img = generate_ResNet_GradCam(images, 0)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(resnet_img)\n",
    "        plt.title(\"ResNet GradCam\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        #gradcam heatmap\n",
    "        heatmap = generate_heatmap_with_tensor(images[0].half())\n",
    "        img = images[0].cpu().detach().permute(1, 2, 0).numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min()) #normalizing\n",
    "        img = np.uint8(255 * img)\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = cv2.addWeighted(heatmap, 0.6, img, 1 - 0.6, 0)\n",
    "        plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('GradCAM with Overlay')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        counter += 1\n",
    "        if counter == 10:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
