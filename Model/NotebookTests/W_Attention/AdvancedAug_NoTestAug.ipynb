{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Attention and using Advanced Aug, but without augmentation on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parameters\n",
    "Here you can change some of the main parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "show_images = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import ops\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'D:\\Estudos\\IC\\CNN\\CNN\\Model')\n",
    "from TrainingDataArrangement import arrange_data\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import CustomDataset\n",
    "from UNetModel import UNet\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "#defining device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):  \n",
    "    random.seed(seed) #setting for albumentations\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(727)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting path references\n",
    "testing_folders = [\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009009\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009010x1000902\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009011\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009014\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009016x1000903\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009023\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009009\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009010x1000902\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009011\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009014\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009016x1000903\\02-non_roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\testing\\tumor\\patch\\640x640\\1009023\\02-non_roi\"\n",
    "]\n",
    "\n",
    "training_folders = [\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\01-roi\",\n",
    "    r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\01-roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009009\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009010x1000902\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009011\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009014\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009016x1000903\\02-non_roi\",\n",
    "    # r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\training\\tumor\\patch\\640x640\\1009023\\02-non_roi\"\n",
    "]\n",
    "\n",
    "updated_training_folders = []\n",
    "updated_testing_folders = []\n",
    "\n",
    "for training_folder, testing_folder in zip(training_folders, testing_folders):\n",
    "    original_training_folder = training_folder + \"\\\\01-original\"\n",
    "    mask_training_folder = training_folder + \"\\\\02-mask\"\n",
    "    updated_training_folders.extend([original_training_folder, mask_training_folder])\n",
    "\n",
    "    original_testing_folder = testing_folder + \"\\\\01-original\"\n",
    "    mask_testing_folder = testing_folder + \"\\\\02-mask\"\n",
    "    updated_testing_folders.extend([original_testing_folder, mask_testing_folder])\n",
    "\n",
    "training_path = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\training\"\n",
    "test_path = r\"D:\\Estudos\\IC\\DataSets\\H&E-stained oral squamous cell carcinoma histological images dataset\\H&E-stained oral squamous cell carcinoma histological images dataset\\appended_folder\\testing\"\n",
    "\n",
    "arrange_data(test_path,updated_testing_folders)\n",
    "arrange_data(training_path,updated_training_folders)\n",
    "\n",
    "#data augmentation\n",
    "augmentation_transform = A.Compose([\n",
    "    #A.ToPIL(),\n",
    "    A.Resize(width = width, height = height, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    A.Transpose(p=0.25),\n",
    "    A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
    "    A.GridDistortion(num_steps=5, distort_limit=(-0.3, 0.3), interpolation=1, border_mode=4, p=0.3),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1, border_mode=4, p=0.3),\n",
    "    A.OpticalDistortion(distort_limit=(-0.05, 0.05), shift_limit=(-0.05, 0.05), interpolation=1, border_mode=4, p=0.3),\n",
    "    A.Perspective(scale=(0.05, 0.1), keep_size=True, pad_mode=0, pad_val=0, mask_pad_val=0, fit_output=False, interpolation=1, p=0.3),\n",
    "    A.PiecewiseAffine (scale=(0.03, 0.05), nb_rows=4, nb_cols=4, interpolation=1, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=0.1),\n",
    "    A.ShiftScaleRotate (shift_limit=(-0.0625, 0.0625), scale_limit=(-0.1, 0.1), rotate_limit=(-45, 45), interpolation=1, border_mode=4, value=0, mask_value=0, rotate_method='largest_box', p=0.15),\n",
    "    ToTensorV2()  # loading image to tensor and normalization\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    #A.ToPIL(),\n",
    "    A.Resize(width = width, height = height, p=1.0),\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    # A.VerticalFlip(p=0.25),\n",
    "    # A.RandomRotate90(p=0.5),\n",
    "    # A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    # A.Transpose(p=0.5),\n",
    "    #A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
    "    ToTensorV2()  # loading image to tensor and normalization\n",
    "])\n",
    "\n",
    "print(\"Showing images:\", show_images)\n",
    "\n",
    "print(\"Getting the images\")\n",
    "training_dataset = CustomDataset.CustomImageDataset(training_path + \"\\\\images\", training_path + \"\\\\masks\", transform=augmentation_transform)\n",
    "test_dataset = CustomDataset.CustomImageDataset(test_path + \"\\\\images\", test_path + \"\\\\masks\", transform=test_transform)\n",
    "\n",
    "print(\"Converting images to tensors\")\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=batch_size, shuffle=True)\n",
    "if(show_images):\n",
    "    num_images_to_display = 10\n",
    "    fig, axs = plt.subplots(num_images_to_display, 2, figsize=(10, 20))\n",
    "    for i in range(num_images_to_display):\n",
    "        train_image, mask_image = training_dataset[i]\n",
    "        train_image = train_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "        axs[i, 0].imshow(train_image)\n",
    "        axs[i, 0].set_title('Train Image')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        mask_image = mask_image.squeeze(0).numpy()\n",
    "        axs[i, 1].imshow(mask_image, cmap='gray')\n",
    "        axs[i, 1].set_title('Mask Image')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "classes = 1\n",
    "model = UNet(channels, classes)\n",
    "input_data = torch.randn(1, channels, width, height)\n",
    "output = model(input_data)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = epochs\n",
    "\n",
    "#training\n",
    "train_losses = []\n",
    "accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "dice = []\n",
    "iou_values = []\n",
    "specificity = []\n",
    "sensitivity = []\n",
    "pq_values = []\n",
    "aji_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "\n",
    "    for images, masks in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = F.binary_cross_entropy(outputs, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #thresholding the prediction values\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        binary_predictions = (outputs > 0.5).float()\n",
    "        \n",
    "        #calculating the correct pixels\n",
    "        correct_predictions += (binary_predictions == masks).sum().item()\n",
    "\n",
    "        total_samples += masks.numel()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%\")\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    val_true_positives = 0\n",
    "    val_true_negatives = 0\n",
    "    val_false_positives = 0\n",
    "    val_false_negatives = 0\n",
    "    val_iou = 0\n",
    "    val_specificity = 0\n",
    "    val_sensitivity = 0\n",
    "    val_pq = 0\n",
    "    val_aji = 0\n",
    "    batch_iou = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in test_dataloader:\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "\n",
    "            val_loss = F.binary_cross_entropy(val_outputs, val_masks)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            #thresholding the prediction values\n",
    "            val_binary_predictions = (val_outputs > 0.5).float()\n",
    "\n",
    "            #calculating the correct pixels\n",
    "            val_correct_predictions += (val_binary_predictions == val_masks).sum().item()\n",
    "            val_total_samples += val_masks.numel()\n",
    "            val_true_negatives = ((val_binary_predictions == 0) & (val_masks == 0)).sum().item()\n",
    "\n",
    "            val_true_positives += ((val_binary_predictions == 1) & (val_masks == 1)).sum().item()\n",
    "            #calculating the false positives\n",
    "            val_false_positives += ((val_binary_predictions == 1) & (val_masks == 0)).sum().item()\n",
    "\n",
    "            #calculating the false negatives\n",
    "            val_false_negatives += ((val_binary_predictions == 0) & (val_masks == 1)).sum().item()\n",
    "\n",
    "            #calculating iou\n",
    "            intersection = torch.logical_and(val_binary_predictions, val_masks).sum().item()\n",
    "            union = torch.logical_or(val_binary_predictions, val_masks).sum().item()\n",
    "            iou = intersection / union if union > 0 else 0.0\n",
    "            batch_iou += iou\n",
    "\n",
    "            #calculating aji\n",
    "            val_aji += (intersection / union) * (val_true_positives/(val_true_positives+val_false_positives+val_false_negatives))\n",
    "\n",
    "    #precision and recall\n",
    "    precision = val_true_positives / (val_true_positives + val_false_positives)\n",
    "    recall = val_true_positives / (val_true_positives + val_false_negatives)\n",
    "\n",
    "    #specificity and sensitivity\n",
    "    val_sensitivity = recall\n",
    "    val_specificity = val_true_negatives / (val_true_negatives + val_false_positives)\n",
    "    specificity.append(val_specificity)\n",
    "    sensitivity.append(val_sensitivity)\n",
    "\n",
    "    #epoch loss and accuracy\n",
    "    val_epoch_loss = val_running_loss / len(test_dataloader)\n",
    "    val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    #dice\n",
    "    val_temp_dice = (2 * val_true_positives) / (2 * val_true_positives + val_false_positives + val_false_negatives)\n",
    "    dice.append(val_temp_dice)\n",
    "\n",
    "    #pq\n",
    "    val_pq = precision * recall\n",
    "    pq_values.append(val_pq)\n",
    "\n",
    "    #iou\n",
    "    iou = batch_iou / len(test_dataloader)\n",
    "    iou_values.append(iou)\n",
    "\n",
    "    #aji\n",
    "    aji = val_aji / len(test_dataloader)\n",
    "    aji_values.append(aji) \n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy * 100:.2f}%, Dice: {val_temp_dice:.4f}%, IOU: {iou:.4f}%, PQ: {val_pq:.4f}, aji {aji:.4f}%, Specificity: {val_specificity:.4f}%, Sensitivity: {val_sensitivity:.4f}%\")\n",
    "    if(show_images):\n",
    "        with torch.no_grad():\n",
    "            for images, masks in test_dataloader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                if torch.any(masks > 0):\n",
    "                    outputs = model(images)\n",
    "                    probs = outputs\n",
    "\n",
    "                    images_np = images.cpu().numpy()\n",
    "                    masks_np = masks.cpu().numpy()\n",
    "                    probs_np = probs.cpu().numpy()\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    preds_np = (probs_np > threshold).astype(np.uint8)\n",
    "                    preds_np_squeezed = np.squeeze(preds_np, axis=1) \n",
    "\n",
    "                    plt.figure(figsize=(16, 4))\n",
    "\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.imshow(images_np[0].transpose((1, 2, 0)))\n",
    "                    plt.imshow(masks_np[0, 0], alpha=0.5, cmap='plasma')\n",
    "                    plt.title(\"Original Image with Ground Truth Mask\")\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.imshow(images_np[0].transpose((1, 2, 0)))\n",
    "                    plt.imshow(preds_np_squeezed[0], alpha=0.5, cmap='plasma')\n",
    "                    plt.title(\"Original Image with Predicted Mask\")\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Charts\n",
    "\n",
    "- **Accuracy**: The number of correct predictions out of the total of predictions. Higher means better.\n",
    "\n",
    "- **Loss**: How well the predictions matched the expected result. Lower means better.\n",
    "\n",
    "- **Dice**: Calculates the similarity between the intersection of two images. Higher means better.\n",
    "\n",
    "- **Intersection over Union (IoU)**: It calculates the overlap between the predicted image and the ground truth, but it also takes in consideration the union of the boxes, while Dice only accounts for the intersection.Higher means better.\n",
    "\n",
    "- **Panoptic Quality (PQ)**: Indicates the performance in segmenting instances accurately. Higher means better.\n",
    "\n",
    "- **Aggregated Jaccard Index (AJI)**: Indicate the performance of the alignment between predicted and ground truth instance boundaries. Higher means better.\n",
    "\n",
    "- **Specificity**: Measures the proportion of actual negatives that are correctly identified. Higher means better.\n",
    "\n",
    "- **Sensitivity**: Measures the proportion of actual positives that are correctly identified. Higher means better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(accuracies, label='Train Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', color='purple')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(dice, label='Dice Coefficient', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Coefficient')\n",
    "plt.title('Dice Coefficient')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.plot(iou_values, label='IoU', color='brown')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('Intersection over Union (IoU)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(pq_values, label='PQ', color='cyan')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PQ')\n",
    "plt.title('PQ')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(aji_values, label='AJI', color='magenta')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AJI')\n",
    "plt.title('Aggregated Jaccard Index (AJI)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(specificity, label='Specificity', color='gray')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Specificity')\n",
    "plt.title('Specificity')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(sensitivity, label='Sensitivity', color='olive')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Sensitivity')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.patches as mpatches\n",
    "if show_images:\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        brightness = 0.5\n",
    "        for images, masks in test_dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            images_normalized = images\n",
    "\n",
    "            outputs = model(images_normalized)\n",
    "            probs = outputs\n",
    "            #probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            images_np = images_normalized.cpu().numpy()\n",
    "            masks_np = masks.cpu().numpy()\n",
    "            probs_np = probs.cpu().numpy()\n",
    "\n",
    "            threshold = 0.5\n",
    "            preds_np = (probs_np > threshold).astype(np.uint8)\n",
    "            preds_np_squeezed = np.squeeze(preds_np, axis=1) \n",
    "\n",
    "            original_image = images_np[0].transpose((1, 2, 0))\n",
    "            ground_truth_mask = masks_np[0, 0]\n",
    "            predicted_mask = preds_np_squeezed[0]\n",
    "            probability_map = probs_np[0, 0]\n",
    "\n",
    "            overlay_gt = original_image.copy()\n",
    "            overlay_gt = original_image * brightness # to make it a little darker\n",
    "            overlay_gt[ground_truth_mask == 1] = [1, 1, 0]\n",
    "\n",
    "            overlay_pred = original_image.copy()\n",
    "            overlay_pred = original_image * brightness\n",
    "            overlay_pred[predicted_mask == 1] = [0, 1, 1]\n",
    "\n",
    "            overlay_diff = original_image.copy()\n",
    "            overlay_diff = original_image * brightness \n",
    "            overlay_diff[(ground_truth_mask == 1) & (predicted_mask == 1)] = [0, 1, 0]  #correct predictions\n",
    "            overlay_diff[(ground_truth_mask == 1) & (predicted_mask == 0)] = [1, 0, 0]  #missed predictions\n",
    "            overlay_diff[(ground_truth_mask == 0) & (predicted_mask == 1)] = [0, 0, 1]  #false positives\n",
    "\n",
    "            plt.figure(figsize=(28, 4))\n",
    "\n",
    "            plt.subplot(1, 7, 1)\n",
    "            plt.imshow(original_image)\n",
    "            plt.title(\"Original Image\")\n",
    "\n",
    "            plt.subplot(1, 7, 2)\n",
    "            plt.imshow(ground_truth_mask, cmap='gray')\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "\n",
    "            plt.subplot(1, 7, 3)\n",
    "            plt.imshow(probability_map, cmap='plasma')\n",
    "            plt.title(\"Probability Map\")\n",
    "\n",
    "            plt.subplot(1, 7, 4)\n",
    "            plt.imshow(predicted_mask, cmap='gray')\n",
    "            plt.title(\"Predicted Mask\")\n",
    "\n",
    "            plt.subplot(1, 7, 5)\n",
    "            plt.imshow(overlay_gt)\n",
    "            plt.title(\"Overlay Ground Truth\")\n",
    "\n",
    "            plt.subplot(1, 7, 6)\n",
    "            plt.imshow(overlay_pred)\n",
    "            plt.title(\"Overlay Pred\")\n",
    "\n",
    "            green_patch = mpatches.Patch(color='green', label='True Positive')\n",
    "            red_patch = mpatches.Patch(color='red', label='False Negative')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='False Positive')\n",
    "            plt.subplot(1, 7, 7)\n",
    "            plt.imshow(overlay_diff)\n",
    "            plt.title(\"Overlay Diff\")\n",
    "            plt.legend(handles=[green_patch, red_patch, blue_patch], loc='upper right')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            counter += 1\n",
    "            if counter == 10:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
